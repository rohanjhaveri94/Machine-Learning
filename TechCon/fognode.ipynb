{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split #This packet splits the data set into training and testing \n",
    "                                                     #dataset with stratified partionong keeping the ratio of both \n",
    "                                                     #the dataset constant \n",
    "\n",
    "from math import sqrt, ceil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline   \n",
    "\n",
    "from copy import copy\n",
    "import time\n",
    "import sys\n",
    "from scipy.io import arff\n",
    "floatPrecision = sys.float_info.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeatherDataExtract():\n",
    "    dataArray = pd.read_csv(\"Final_dataset.csv\", delimiter=\",\", header=None)\n",
    "    Data_Y = dataArray.iloc[0:10190, 3]                    #labels\n",
    "    Data_X = dataArray.iloc[0:10190, 0:3]                  #features\n",
    "    return Data_X, Data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_X, Data_Y = WeatherDataExtract()\n",
    "Xtrain, Xtest, Ttrain, Ttest = train_test_split(Data_X, Data_Y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing\n",
    "Xtrain_mean = Xtrain.mean(axis=0)\n",
    "Xtrain_std = Xtrain.std(axis=0)\n",
    "temp=Xtrain - Xtrain_mean\n",
    "Xtrain_standardized = (temp)/Xtrain_std\n",
    "a = isnan(Xtrain_standardized)\n",
    "Xtrain_standardized[a] = 0.000000001\n",
    "\n",
    "Xtest_standardized = (Xtest - Xtrain_mean)/Xtrain_std\n",
    "a = isnan(Xtest_standardized)\n",
    "Xtest_standardized[a] = 0.000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the common activation functions:\n",
    "\n",
    "def logistic(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def logistic_deriv(x):\n",
    "    return logistic(x)*(1-logistic(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork :\n",
    "    def __init__(self, architecture, activation='logistic') :\n",
    "        self.architecture = architecture\n",
    "        if activation == 'logistic':\n",
    "            self.activation = logistic\n",
    "            self.activation_deriv = logistic_deriv\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_deriv = tanh_deriv\n",
    "        elif activation == 'relu':\n",
    "            self.activation = relu\n",
    "            self.activation_deriv = relu_deriv\n",
    "        else :\n",
    "            raise ValueError('Activation does not match options')\n",
    "        self.initialize_weights()\n",
    "    \n",
    "    def shuffle_set(self, X, y):\n",
    "        \"\"\"Shuffle training data\"\"\"\n",
    "        r = np.random.permutation(len(y))\n",
    "        return X[r], y[r]\n",
    "        \n",
    "    def initialize_weights(self) :\n",
    "        W = {}\n",
    "        b = {}\n",
    "        for l in range(1, len(self.architecture)):\n",
    "            W[l] = np.random.random((self.architecture[l], self.architecture[l-1]))\n",
    "            b[l] = np.random.random((self.architecture[l],))\n",
    "        self.W, self.b = W, b\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = {1: x}\n",
    "        s = {}\n",
    "        for l in range(1, len(self.W) + 1):\n",
    "            s[l+1] = self.W[l].dot(h[l]) + self.b[l]\n",
    "            h[l+1] = self.activation(s[l+1])\n",
    "        return h, s\n",
    "        \n",
    "    def init_delta_values(self):\n",
    "        delta_W = {}\n",
    "        delta_b = {}\n",
    "        for l in range(1, len(self.architecture)):\n",
    "            delta_W[l] = np.zeros((self.architecture[l], self.architecture[l-1]))\n",
    "            delta_b[l] = np.zeros((self.architecture[l],))\n",
    "        return delta_W, delta_b\n",
    "    \n",
    "    def calculate_output_layer_entropy(self, y, h_out):\n",
    "        return -np.sum(y*(np.log(h_out+1e-6)))\n",
    "\n",
    "    def calculate_output_layer_delta(self, y, h_out, s_out):\n",
    "        return -(y-h_out) * self.activation_deriv(s_out)\n",
    "    \n",
    "    def calculate_output_layer_ce_delta(self, y, h_out, s_out):\n",
    "        return -(y/(h_out+1e-6)) * self.activation_deriv(s_out)\n",
    "\n",
    "    def calculate_hidden_delta(self, delta_plus_1, w_l, s_l):\n",
    "        return np.dot(np.transpose(w_l), delta_plus_1) * self.activation_deriv(s_l)\n",
    "\n",
    "    def fit(self, X, y, num_iterations=3000, alpha=0.25, weightDecay=0.00, cross_entropy= False, stochastic_gradient=False):\n",
    "        iterations = 0\n",
    "        N = len(y)\n",
    "        avg_cost_func = []\n",
    "        while iterations < num_iterations :\n",
    "            if stochastic_gradient:\n",
    "                X, y = self.shuffle_set(X,y)\n",
    "            delta_W, delta_b = self.init_delta_values()\n",
    "            avg_cost = 0\n",
    "            for i in range(len(y)):\n",
    "                delta = {}\n",
    "                # perform the feed forward pass and return the stored h and z values, to be used in the\n",
    "                # gradient descent step\n",
    "                h, s = self.forward(X[i, :])\n",
    "                # backpropagate the errors\n",
    "                for l in range(len(self.architecture), 0, -1):\n",
    "                    if l == len(self.architecture):\n",
    "                        if cross_entropy:\n",
    "                            delta[l] = self.calculate_output_layer_ce_delta(y[i,:], h[l], s[l])\n",
    "                        else:\n",
    "                            delta[l] = self.calculate_output_layer_delta(y[i,:], h[l], s[l])\n",
    "                        avg_cost += (np.linalg.norm((y[i,:]-h[l])) / N)\n",
    "                    else:\n",
    "                        if l > 1:\n",
    "                            delta[l] = self.calculate_hidden_delta(delta[l+1], self.W[l], s[l])\n",
    "                        if stochastic_gradient:\n",
    "                            delta_W[l] = np.dot(delta[l+1][:,np.newaxis], np.transpose(h[l][:,np.newaxis]))\n",
    "                            delta_b[l] = delta[l+1]\n",
    "                            self.W[l] += -alpha * delta_W[l]\n",
    "                            self.b[l] += -alpha * delta_b[l]\n",
    "                        else:\n",
    "                            delta_W[l] += (np.dot(delta[l+1][:,np.newaxis], np.transpose(h[l][:,np.newaxis])) + (weightDecay*self.W[l]))\n",
    "                            delta_b[l] += (delta[l+1] + (weightDecay*self.b[l]))\n",
    "            if not stochastic_gradient:\n",
    "                # perform the gradient descent step for the weights in each layer\n",
    "                for l in range(len(self.architecture) - 1, 0, -1):\n",
    "                    self.W[l] += -alpha * (1.0/N * delta_W[l]) \n",
    "                    self.b[l] += -alpha * (1.0/N * delta_b[l])                    \n",
    "            # complete the average cost calculation\n",
    "            avg_cost_func.append(avg_cost)\n",
    "            iterations += 1\n",
    "        return avg_cost_func\n",
    "\n",
    "    def predict(self, X):\n",
    "        N = X.shape[0]\n",
    "        y = np.zeros((N,))\n",
    "        for i in range(N):\n",
    "            h, _ = self.forward(X[i, :])\n",
    "            y[i] = np.argmax(h[len(self.architecture)])\n",
    "        return y\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        N = X.shape[0]\n",
    "        scores = np.zeros((N,self.architecture[-1]))\n",
    "        for i in range(N):\n",
    "            h, _ = self.forward(X[i, :])\n",
    "            scores[i]=h[len(self.architecture)]\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to vectors\n",
    "Ttrain = Ttrain.astype(int)\n",
    "#print(Ttrain)\n",
    "Ttest = Ttest.astype(int)\n",
    "Ttrain = list(Ttrain)\n",
    "Ttest = list(Ttest)\n",
    "y_vec_train = y_to_vect(Ttrain)\n",
    "y_vec_test = y_to_vect(Ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(0, slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5f549404e47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0marchitecture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcost_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_standardized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vec_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_standardized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0maccuracy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_vec_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_predict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0392726379a3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, num_iterations, alpha, weightDecay, cross_entropy, stochastic_gradient)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# perform the feed forward pass and return the stored h and z values, to be used in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;31m# gradient descent step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# backpropagate the errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2655\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(0, slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "# hidden units for single layer\n",
    "hn=[1,10,20,30,50,100]\n",
    "accuracy_train=[]\n",
    "accuracy_test=[]\n",
    "for i in hn:\n",
    "    architecture = [784,i,10]\n",
    "    network = NeuralNetwork(architecture, 'logistic')\n",
    "    cost_function = network.fit(Xtrain_standardized, y_vec_train, 1000)\n",
    "    train_predict = network.predict(Xtrain_standardized)\n",
    "    accuracy_train.append(accuracy_score(y_vec_train, train_predict) * 100)\n",
    "    test_predict = network.predict(Xtest_standardized)\n",
    "    accuracy_test.append(accuracy_score(y_vec_test, test_predict) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
